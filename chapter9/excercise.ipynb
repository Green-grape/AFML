{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a762a5c9",
   "metadata": {},
   "source": [
    "9.1 Using the function getTestData from Chapter 8, form a synthetic dataset of\n",
    "10,000 observations with 10 features, where 5 are informative and 5 are noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed2c93",
   "metadata": {},
   "source": [
    "(a) Use GridSearchCV on 10-fold CV to find the C, gamma optimal hyper-\n",
    "parameters on a SVC with RBF kernel, where param_grid={'C':[1E-\n",
    "2,1E-1,1,10,100],'gamma':[1E-2,1E-1,1,10,100]} and the scor-\n",
    "ing function is neg_log_loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f9f67c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 I_0       I_1       I_2       I_3       I_4  \\\n",
      "1997-12-27 19:28:26.526902  2.105359  2.861661  0.104159  0.686149  1.369429   \n",
      "1997-12-28 19:28:26.526902 -0.330754  1.464379 -1.405119  0.396713 -1.722305   \n",
      "1997-12-29 19:28:26.526902 -0.461334 -0.160432 -2.169501 -0.137535  0.398229   \n",
      "1997-12-30 19:28:26.526902 -1.573667  3.110105  0.073939  1.232501  1.069429   \n",
      "1997-12-31 19:28:26.526902  0.528677  1.538982 -1.603758  2.056413  0.777722   \n",
      "...                              ...       ...       ...       ...       ...   \n",
      "2025-05-09 19:28:26.526902  0.340564 -2.226446 -1.717539  1.920408 -2.453376   \n",
      "2025-05-10 19:28:26.526902 -2.003425 -2.504737 -2.081414  1.236596  0.386712   \n",
      "2025-05-11 19:28:26.526902 -3.191242 -0.151656 -0.376615 -0.944432 -0.663403   \n",
      "2025-05-12 19:28:26.526902 -2.116680 -0.735869 -0.858766  0.371223 -1.769760   \n",
      "2025-05-13 19:28:26.526902 -1.717428 -3.589082 -2.411008  2.244037  0.664538   \n",
      "\n",
      "                                 N_5       N_6       N_7       N_8       N_9  \n",
      "1997-12-27 19:28:26.526902 -4.441480 -0.741647 -0.278979 -1.860566  0.909540  \n",
      "1997-12-28 19:28:26.526902 -0.665029 -2.832873 -0.396742  2.455228  0.700720  \n",
      "1997-12-29 19:28:26.526902 -0.721387 -0.934116 -1.097145  0.157145 -1.699373  \n",
      "1997-12-30 19:28:26.526902 -2.910245 -0.248054  1.167458 -0.644594 -0.304476  \n",
      "1997-12-31 19:28:26.526902 -3.060848 -2.247537  0.682256 -0.644368  0.280994  \n",
      "...                              ...       ...       ...       ...       ...  \n",
      "2025-05-09 19:28:26.526902  2.411971 -3.542261 -0.162699 -1.196350  0.033094  \n",
      "2025-05-10 19:28:26.526902  1.878392 -0.466397 -0.213865 -1.179264 -0.823565  \n",
      "2025-05-11 19:28:26.526902  2.007288  0.757142 -0.573801 -2.520696  0.932842  \n",
      "2025-05-12 19:28:26.526902  2.345493 -1.285245  1.107749 -0.181164  0.245925  \n",
      "2025-05-13 19:28:26.526902  2.244828 -0.794343 -1.658584 -0.518984 -0.211644  \n",
      "\n",
      "[10000 rows x 10 columns]                             bin       w                         t1\n",
      "1997-12-27 19:28:26.526902    0  0.0001 1997-12-27 19:28:26.526902\n",
      "1997-12-28 19:28:26.526902    0  0.0001 1997-12-28 19:28:26.526902\n",
      "1997-12-29 19:28:26.526902    0  0.0001 1997-12-29 19:28:26.526902\n",
      "1997-12-30 19:28:26.526902    0  0.0001 1997-12-30 19:28:26.526902\n",
      "1997-12-31 19:28:26.526902    0  0.0001 1997-12-31 19:28:26.526902\n",
      "...                         ...     ...                        ...\n",
      "2025-05-09 19:28:26.526902    1  0.0001 2025-05-09 19:28:26.526902\n",
      "2025-05-10 19:28:26.526902    1  0.0001 2025-05-10 19:28:26.526902\n",
      "2025-05-11 19:28:26.526902    1  0.0001 2025-05-11 19:28:26.526902\n",
      "2025-05-12 19:28:26.526902    1  0.0001 2025-05-12 19:28:26.526902\n",
      "2025-05-13 19:28:26.526902    1  0.0001 2025-05-13 19:28:26.526902\n",
      "\n",
      "[10000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from datetime import datetime\n",
    "from utils import PurgedKFold\n",
    "\n",
    "def get_test_data(n_features=10, n_informative=5, n_samples=10000):\n",
    "    X, cont=make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_informative, random_state=0, shuffle=False)\n",
    "    t_index=pd.date_range(periods=n_samples, freq='D', end=datetime.today())\n",
    "    X, cont=pd.DataFrame(X, index=t_index), pd.Series(cont, index=t_index).to_frame(name='bin')\n",
    "    X.columns=[f'I_{i}' for i in range(n_informative)]+[f'N_{i}' for i in range(n_informative, n_features)]\n",
    "    cont['w']=1/len(cont)\n",
    "    cont['t1']=pd.Series(cont.index, index=cont.index)\n",
    "    return X, cont\n",
    "\n",
    "X, cont = get_test_data(n_features=10, n_informative=5, n_samples=10000)\n",
    "print(X, cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcbdfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AFML/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.01} -0.3727089525170734\n",
      "{'mean_fit_time': array([ 9.17368157,  9.41541514,  9.1325393 ,  9.21862061,  7.26268544,\n",
      "        9.63701828,  9.72935259,  9.43547769,  9.57638218,  7.24953258,\n",
      "        9.69084883,  9.57894535,  9.2583168 ,  9.56063757,  7.26230938,\n",
      "        9.51589711,  9.57695706,  9.52711604,  9.66317406,  8.35909042,\n",
      "        6.50851345,  7.50539181, 10.16300895, 12.46835697,  9.11296785]), 'std_fit_time': array([0.42471518, 0.74248626, 1.18435859, 0.92663503, 0.36893453,\n",
      "       0.42876045, 0.3846183 , 1.11289177, 0.38060618, 0.38968233,\n",
      "       0.67779845, 0.67934416, 0.8809273 , 0.47216704, 0.43838611,\n",
      "       0.83625234, 0.74688685, 1.1547238 , 0.39840316, 0.31269165,\n",
      "       0.33987558, 0.65383477, 0.47855205, 1.01320179, 0.54353153]), 'mean_score_time': array([0.34169986, 0.34902806, 0.36442113, 0.34658749, 0.33390081,\n",
      "       0.34793735, 0.35568216, 0.35592337, 0.35558095, 0.33323262,\n",
      "       0.36152432, 0.35665302, 0.35717497, 0.37553806, 0.34589481,\n",
      "       0.3431469 , 0.3479037 , 0.35379279, 0.36060717, 0.3832242 ,\n",
      "       0.23659899, 0.25045805, 0.37100677, 0.4002934 , 0.30307124]), 'std_score_time': array([0.04629514, 0.03445441, 0.05093162, 0.03577386, 0.02435992,\n",
      "       0.04608659, 0.04304714, 0.02067869, 0.01880121, 0.02817934,\n",
      "       0.0593161 , 0.04054544, 0.03952896, 0.02612022, 0.03145388,\n",
      "       0.03531608, 0.07544093, 0.05145839, 0.01639313, 0.02492184,\n",
      "       0.02649891, 0.02362893, 0.0233871 , 0.02839134, 0.05839588]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
      "                   100.0, 100.0, 100.0, 100.0, 100.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_gamma': masked_array(data=[0.01, 0.1, 1.0, 10.0, 100.0, 0.01, 0.1, 1.0, 10.0,\n",
      "                   100.0, 0.01, 0.1, 1.0, 10.0, 100.0, 0.01, 0.1, 1.0,\n",
      "                   10.0, 100.0, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'params': [{'C': 0.01, 'gamma': 0.01}, {'C': 0.01, 'gamma': 0.1}, {'C': 0.01, 'gamma': 1}, {'C': 0.01, 'gamma': 10}, {'C': 0.01, 'gamma': 100}, {'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 1}, {'C': 0.1, 'gamma': 10}, {'C': 0.1, 'gamma': 100}, {'C': 1, 'gamma': 0.01}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 1}, {'C': 1, 'gamma': 10}, {'C': 1, 'gamma': 100}, {'C': 10, 'gamma': 0.01}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 1}, {'C': 10, 'gamma': 10}, {'C': 10, 'gamma': 100}, {'C': 100, 'gamma': 0.01}, {'C': 100, 'gamma': 0.1}, {'C': 100, 'gamma': 1}, {'C': 100, 'gamma': 10}, {'C': 100, 'gamma': 100}], 'split0_test_score': array([-0.15816913, -0.10796299, -0.02015091, -0.82453673, -0.82456845,\n",
      "       -0.11348644, -0.17996915, -0.01880335, -0.82453673, -0.82456684,\n",
      "       -0.09442707, -0.09662276, -0.05427427, -0.09787678, -0.82456889,\n",
      "       -0.09267801, -0.09122723, -0.18152672, -0.77220133, -0.82453673,\n",
      "       -0.14746939, -0.13143663, -0.16369927, -0.8171809 , -0.82774485]), 'split1_test_score': array([-0.18950225, -0.10186463, -0.09670883, -0.8217482 , -0.8223065 ,\n",
      "       -0.13051441, -0.18744558, -0.09670885, -0.08636985, -0.82230561,\n",
      "       -0.11589581, -0.1088043 , -0.08045245, -0.09670867, -0.82230649,\n",
      "       -0.11279112, -0.10406035, -0.17091759, -0.77707399, -0.82230559,\n",
      "       -0.16362261, -0.13836884, -0.1551295 , -0.8133725 , -0.82682181]), 'split2_test_score': array([-0.33171273, -0.35578652, -0.57703826, -0.69321842, -0.6932297 ,\n",
      "       -0.24251821, -0.271207  , -0.69314718, -0.69314718, -0.69322912,\n",
      "       -0.23167572, -0.25211881, -0.69314718, -0.69754746, -0.69310711,\n",
      "       -0.23081876, -0.25090655, -0.48044095, -0.70183843, -0.69322977,\n",
      "       -0.18328565, -0.20745104, -0.5041673 , -0.68850925, -0.69255083]), 'split3_test_score': array([-0.09474842, -0.57575429, -2.77185273, -0.82558986, -0.82155944,\n",
      "       -0.14179665, -0.29802766, -2.72737758, -0.96650802, -0.82153575,\n",
      "       -0.16661761, -0.35780338, -2.52158052, -1.02108011, -0.82152882,\n",
      "       -0.16853919, -0.37052447, -0.78759575, -0.97380817, -0.82152882,\n",
      "       -0.24858857, -0.37733695, -0.78325728, -0.82596278, -0.82603271]), 'split4_test_score': array([-0.07534499, -0.45686625, -2.70996403, -0.80245286, -0.7987278 ,\n",
      "       -0.13552678, -0.24169408, -2.68615807, -0.83313079, -0.79872281,\n",
      "       -0.15770173, -0.29855951, -2.29005962, -1.60939703, -0.79870287,\n",
      "       -0.15959361, -0.31247519, -0.69677474, -0.92826592, -0.79817963,\n",
      "       -0.241583  , -0.3409931 , -0.69762072, -0.81379209, -0.80298709]), 'split5_test_score': array([-1.03232182, -1.01820317, -0.11605258, -0.82246618, -0.82305508,\n",
      "       -0.87836447, -1.01153187, -0.11911541, -0.0543549 , -0.82296351,\n",
      "       -0.75025995, -0.73037186, -0.17941118, -0.02762848, -0.82299642,\n",
      "       -0.74728221, -0.70125085, -0.48250647, -0.80253775, -0.82218709,\n",
      "       -0.90677934, -0.78591158, -0.48735017, -0.82036646, -0.82749302]), 'split6_test_score': array([-1.17708303, -1.11508365, -0.12273476, -0.82328006, -0.82331136,\n",
      "       -0.96445267, -1.12348931, -0.10679096, -0.82328006, -0.82328006,\n",
      "       -0.79910008, -0.77453251, -0.2304082 , -0.26270516, -0.82331145,\n",
      "       -0.79319162, -0.74964066, -0.53936779, -0.80392203, -0.82240425,\n",
      "       -0.9865898 , -0.85221212, -0.52939828, -0.81867349, -0.82772508]), 'split7_test_score': array([-1.23241284, -1.27549183, -0.45235263, -0.69320379, -0.69325866,\n",
      "       -0.83158173, -0.86535628, -0.40649307, -0.69206137, -0.69314718,\n",
      "       -0.78457187, -0.75092042, -0.44572207, -0.69342277, -0.69325862,\n",
      "       -0.79127758, -0.81942348, -0.48190354, -0.68625953, -0.69258037,\n",
      "       -0.60215097, -0.51751464, -0.61674432, -0.66738207, -0.69258006]), 'split8_test_score': array([-0.14328328, -0.52179001, -2.0472085 , -0.82571877, -0.82181151,\n",
      "       -0.28253924, -0.29351352, -1.9594167 , -0.83405895, -0.82181149,\n",
      "       -0.31461764, -0.33349889, -1.58579997, -1.1819983 , -0.82181153,\n",
      "       -0.31690077, -0.33762473, -0.27971857, -0.83323231, -0.82181219,\n",
      "       -0.62984647, -0.52017683, -0.273241  , -0.79968845, -0.82632065]), 'split9_test_score': array([-0.13781751, -0.50094752, -1.59432251, -0.80812793, -0.80805224,\n",
      "       -0.28073043, -0.27805819, -1.64899967, -0.98803573, -0.80805069,\n",
      "       -0.31222205, -0.31744818, -1.35183124, -1.11752793, -0.80735088,\n",
      "       -0.31640858, -0.32328299, -0.28873139, -0.77941981, -0.80802523,\n",
      "       -0.62571978, -0.51194485, -0.28618157, -0.79415592, -0.81227138]), 'mean_test_score': array([-0.4572396 , -0.60297509, -1.05083857, -0.79403428, -0.79298807,\n",
      "       -0.4001511 , -0.47502926, -1.04630108, -0.67954836, -0.79296131,\n",
      "       -0.37270895, -0.40206806, -0.94326867, -0.68058927, -0.79289431,\n",
      "       -0.37294814, -0.40604165, -0.43894835, -0.80585593, -0.79267897,\n",
      "       -0.47356356, -0.43833466, -0.44967894, -0.78590839, -0.79625275]), 'std_test_score': array([0.45874977, 0.38513485, 1.06269794, 0.05095286, 0.05048276,\n",
      "       0.32830661, 0.35064504, 1.04623498, 0.31776106, 0.05049598,\n",
      "       0.27440926, 0.24383027, 0.88437597, 0.51988959, 0.05048101,\n",
      "       0.27419064, 0.24738776, 0.1973837 , 0.08469901, 0.05050116,\n",
      "       0.3010105 , 0.23688807, 0.20923891, 0.05492541, 0.05242868]), 'rank_test_score': array([ 9, 12, 25, 20, 19,  3, 11, 24, 13, 18,  1,  4, 23, 14, 17,  2,  5,\n",
      "        7, 22, 16, 10,  6,  8, 15, 21], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid={\n",
    "    'C':[1e-2, 1e-1, 1, 10, 100],\n",
    "    'gamma':[1e-2, 1e-1, 1, 10, 100]\n",
    "}\n",
    "cv=PurgedKFold(n_splits=10, t1=cont['t1'], pct_embargo=0.01)\n",
    "grid=GridSearchCV(estimator=SVC(probability=True), param_grid=param_grid, scoring='neg_log_loss', cv=cv, n_jobs=-1)\n",
    "grid.fit(X=X, y=cont['bin'], sample_weight=cont['w'])\n",
    "print(grid.best_params_, grid.best_score_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f4c96",
   "metadata": {},
   "source": [
    "(b) How many nodes are there in the grid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02672011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node cnt: 25\n"
     ]
    }
   ],
   "source": [
    "print('node cnt:', len(grid.cv_results_['params']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6cfb4",
   "metadata": {},
   "source": [
    "(c) How may fits did it take to find the optimal solution ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcd7b462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit cnt: 250\n"
     ]
    }
   ],
   "source": [
    "print('fit cnt:', len(grid.cv_results_['params']) * len([key for key in grid.cv_results_.keys() if key.startswith('split')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9729fdf5",
   "metadata": {},
   "source": [
    "(d) How long did it take to find this solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f603b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fit time: 236.21311922073363\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cpu_cnt=os.cpu_count()\n",
    "split_cnt=len([key for key in grid.cv_results_.keys() if key.startswith('split')])\n",
    "total_fit_time=[grid.cv_results_[time_key].sum()*split_cnt for time_key in grid.cv_results_.keys() if time_key.startswith('mean') and time_key.endswith('time')]\n",
    "print('total fit time:', sum(total_fit_time)/cpu_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5040f2",
   "metadata": {},
   "source": [
    "(e) How can you access the optimal result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8e9600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 SVC(C=1, gamma=0.01, probability=True)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_index_, grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f58fb",
   "metadata": {},
   "source": [
    "(f) What is the CV score of the optimal parameter combation ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f34a4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3727089525170734\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_['mean_test_score'][grid.best_index_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d930e3a",
   "metadata": {},
   "source": [
    "(g) How can you pass sample weights to the SVC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856254ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a74829",
   "metadata": {},
   "source": [
    "9.2 Using the same dataset from exercise 1,   \n",
    "Use RandomizedSearchCV on 10-fold CV to find the C,  \n",
    "gamma optimal hyper-parameters on an SVC with RBF kernel,  \n",
    "where param_distributions={'C':logUniform(a=1E-2,b=1E2),'gamma':logUniform(a=1E-2,b=1E2)},n_iter=25 and neg_log_loss is the scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b060c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AFML/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': np.float64(1.9940757492152932), 'gamma': np.float64(0.019454583161927167)} -0.3650842741167315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "param_distributions={\n",
    "    'C':loguniform(1e-2, 100),\n",
    "    'gamma':loguniform(1e-2, 100)\n",
    "}\n",
    "cv=PurgedKFold(n_splits=10, t1=cont['t1'], pct_embargo=0.01)\n",
    "randomnized=RandomizedSearchCV(estimator=SVC(probability=True), param_distributions=param_distributions, scoring='neg_log_loss', cv=cv, n_jobs=-1, n_iter=25)\n",
    "randomnized.fit(X=X, y=cont['bin'], sample_weight=cont['w'])\n",
    "print(randomnized.best_params_, randomnized.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3b359",
   "metadata": {},
   "source": [
    "(b) How long did it ake to find this solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f0f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total fit time: 247.4079880952835\n"
     ]
    }
   ],
   "source": [
    "cpu_cnt=os.cpu_count()\n",
    "split_cnt=len([key for key in randomnized.cv_results_.keys() if key.startswith('split')])\n",
    "total_fit_time=[randomnized.cv_results_[time_key].sum()*split_cnt for time_key in randomnized.cv_results_.keys() if time_key.startswith('mean') and time_key.endswith('time')]\n",
    "print('total fit time:', sum(total_fit_time)/cpu_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b470ad2",
   "metadata": {},
   "source": [
    "(c) Is the optimal parameter combination similar to the one found in exercise1 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23375e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params {'C': np.float64(1.9940757492152932), 'gamma': np.float64(0.019454583161927167)}\n"
     ]
    }
   ],
   "source": [
    "print('best params', randomnized.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c45cc04",
   "metadata": {},
   "source": [
    "(d) What is the CV score of the optimal parameter combination? \n",
    "How does it compare to the CV score from exercise 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb65d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best scores -0.3650842741167315\n"
     ]
    }
   ],
   "source": [
    "print('best scores', randomnized.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52b467",
   "metadata": {},
   "source": [
    "9.3 From exercise 1,\n",
    "(a) Compute the Sharpe ratio of the resulting in-sample forecasts,from point 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0210f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharpe ratio(neg log loss): 15.708096270562903 lowest: 0.9888403198543811\n"
     ]
    }
   ],
   "source": [
    "sharpe_ratios=[abs(grid.cv_results_['mean_test_score'][i])/grid.cv_results_['std_test_score'][i]  for i in range(len(grid.cv_results_['mean_test_score']))]\n",
    "print('sharpe ratio(neg log loss):', max(sharpe_ratios), 'lowest:', min(sharpe_ratios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7d2a2",
   "metadata": {},
   "source": [
    "(b) Repeat point1.a,this time with accuracy as the scoring function.\n",
    "Compute the in-sample forecasts derived from the hyper-tuned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88b93a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AFML/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.01} 0.7971\n",
      "{'mean_fit_time': array([10.26034508,  9.54598763,  9.92795203,  9.74459569,  7.29867718,\n",
      "        9.67603126,  9.86873162,  9.31503923,  9.48041127,  7.40314298,\n",
      "        9.63850091, 10.08881316,  9.3715544 , 12.03973701,  8.93130822,\n",
      "       10.11274588,  9.95934966,  9.70562444, 10.056634  ,  8.50154657,\n",
      "        6.66883671,  7.66906261, 10.3028614 , 12.67197356,  9.30520582]), 'std_fit_time': array([0.56172927, 1.33446501, 0.6701515 , 0.43444584, 0.40580352,\n",
      "       0.46958278, 1.47707838, 1.575544  , 1.67054981, 0.76871194,\n",
      "       0.48040539, 0.45674308, 1.07295777, 1.46342118, 0.81816766,\n",
      "       0.80576297, 0.4807356 , 0.49022664, 0.40382943, 0.2567342 ,\n",
      "       0.35704953, 0.95738665, 1.08408997, 1.02960466, 0.82249923]), 'mean_score_time': array([0.36386883, 0.3692677 , 0.3724489 , 0.361078  , 0.34397075,\n",
      "       0.34345453, 0.3817744 , 0.31825464, 0.36829109, 0.34839568,\n",
      "       0.3291229 , 0.36590154, 0.35047443, 0.4815012 , 0.39112678,\n",
      "       0.36163054, 0.33958647, 0.35918088, 0.37314601, 0.38136845,\n",
      "       0.236362  , 0.24238474, 0.36877987, 0.42391207, 0.31613271]), 'std_score_time': array([0.05358744, 0.03622139, 0.03848953, 0.02166728, 0.03814723,\n",
      "       0.04064526, 0.0592802 , 0.05146626, 0.05636825, 0.0442095 ,\n",
      "       0.03973419, 0.04004946, 0.04469729, 0.10182944, 0.04478813,\n",
      "       0.05521309, 0.03027729, 0.02845768, 0.02484904, 0.0146667 ,\n",
      "       0.01726551, 0.03374948, 0.04587887, 0.03943548, 0.06557121]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
      "                   100.0, 100.0, 100.0, 100.0, 100.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'param_gamma': masked_array(data=[0.01, 0.1, 1.0, 10.0, 100.0, 0.01, 0.1, 1.0, 10.0,\n",
      "                   100.0, 0.01, 0.1, 1.0, 10.0, 100.0, 0.01, 0.1, 1.0,\n",
      "                   10.0, 100.0, 0.01, 0.1, 1.0, 10.0, 100.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value=1e+20), 'params': [{'C': 0.01, 'gamma': 0.01}, {'C': 0.01, 'gamma': 0.1}, {'C': 0.01, 'gamma': 1}, {'C': 0.01, 'gamma': 10}, {'C': 0.01, 'gamma': 100}, {'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 1}, {'C': 0.1, 'gamma': 10}, {'C': 0.1, 'gamma': 100}, {'C': 1, 'gamma': 0.01}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 1}, {'C': 1, 'gamma': 10}, {'C': 1, 'gamma': 100}, {'C': 10, 'gamma': 0.01}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 1}, {'C': 10, 'gamma': 10}, {'C': 10, 'gamma': 100}, {'C': 100, 'gamma': 0.01}, {'C': 100, 'gamma': 0.1}, {'C': 100, 'gamma': 1}, {'C': 100, 'gamma': 10}, {'C': 100, 'gamma': 100}], 'split0_test_score': array([0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
      "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.009, 0.001, 0.001,\n",
      "       0.001, 0.001, 0.926, 0.919, 0.001, 0.001, 0.001]), 'split1_test_score': array([0.006, 0.006, 0.006, 0.006, 0.006, 0.006, 0.006, 0.006, 0.006,\n",
      "       0.006, 0.006, 0.006, 0.006, 0.006, 0.006, 0.021, 0.006, 0.006,\n",
      "       0.006, 0.006, 0.921, 0.913, 0.006, 0.006, 0.006]), 'split2_test_score': array([0.499, 0.499, 0.499, 0.499, 0.499, 0.499, 0.499, 0.499, 0.499,\n",
      "       0.499, 0.499, 0.499, 0.499, 0.499, 0.499, 0.875, 0.522, 0.499,\n",
      "       0.499, 0.499, 0.953, 0.941, 0.499, 0.499, 0.499]), 'split3_test_score': array([0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
      "       0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.03 , 0.005, 0.005,\n",
      "       0.005, 0.005, 0.929, 0.843, 0.005, 0.005, 0.005]), 'split4_test_score': array([0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002,\n",
      "       0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.124, 0.002, 0.002,\n",
      "       0.002, 0.002, 0.941, 0.871, 0.002, 0.002, 0.002]), 'split5_test_score': array([0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004,\n",
      "       0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.088, 0.004, 0.004,\n",
      "       0.004, 0.004, 0.539, 0.54 , 0.004, 0.004, 0.004]), 'split6_test_score': array([0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.004,\n",
      "       0.004, 0.004, 0.004, 0.004, 0.004, 0.004, 0.101, 0.004, 0.004,\n",
      "       0.004, 0.004, 0.544, 0.544, 0.004, 0.004, 0.004]), 'split7_test_score': array([0.498, 0.498, 0.498, 0.498, 0.498, 0.498, 0.498, 0.498, 0.498,\n",
      "       0.498, 0.498, 0.498, 0.498, 0.498, 0.498, 0.73 , 0.564, 0.498,\n",
      "       0.498, 0.498, 0.748, 0.783, 0.498, 0.498, 0.498]), 'split8_test_score': array([0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
      "       0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
      "       0.005, 0.005, 0.739, 0.813, 0.005, 0.005, 0.005]), 'split9_test_score': array([0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
      "       0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
      "       0.005, 0.005, 0.731, 0.801, 0.005, 0.005, 0.005]), 'mean_test_score': array([0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1029,\n",
      "       0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1029, 0.1988,\n",
      "       0.1118, 0.1029, 0.1029, 0.1029, 0.7971, 0.7968, 0.1029, 0.1029,\n",
      "       0.1029]), 'std_test_score': array([0.19780518, 0.19780518, 0.19780518, 0.19780518, 0.19780518,\n",
      "       0.19780518, 0.19780518, 0.19780518, 0.19780518, 0.19780518,\n",
      "       0.19780518, 0.19780518, 0.19780518, 0.19780518, 0.19780518,\n",
      "       0.30628477, 0.21580908, 0.19780518, 0.19780518, 0.19780518,\n",
      "       0.15336457, 0.13681871, 0.19780518, 0.19780518, 0.19780518]), 'rank_test_score': array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 1, 2,\n",
      "       5, 5, 5], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "param_grid={\n",
    "    'C':[1e-2, 1e-1, 1, 10, 100],\n",
    "    'gamma':[1e-2, 1e-1, 1, 10, 100]\n",
    "}\n",
    "cv=PurgedKFold(n_splits=10, t1=cont['t1'], pct_embargo=0.01)\n",
    "grid=GridSearchCV(estimator=SVC(probability=True), param_grid=param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid.fit(X=X, y=cont['bin'], sample_weight=cont['w'])\n",
    "print(grid.best_params_, grid.best_score_)\n",
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99efe13",
   "metadata": {},
   "source": [
    "(c) What scoring method leads tohigher (in-sample) Sharpe ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72b77684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharpe ratio(accuracy): 5.823764800584609 lowest: 0.5180504861625214\n"
     ]
    }
   ],
   "source": [
    "sharpe_ratios=[abs(grid.cv_results_['mean_test_score'][i])/grid.cv_results_['std_test_score'][i]  for i in range(len(grid.cv_results_['mean_test_score']))]\n",
    "print('sharpe ratio(accuracy):', max(sharpe_ratios), 'lowest:', min(sharpe_ratios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03420ec6",
   "metadata": {},
   "source": [
    "9.4 From exercise 2,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56122cf6",
   "metadata": {},
   "source": [
    "(a) Compute the Sharpe ratio of the resulting in-sample forecasts, from point\n",
    "2.a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b3afe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharpe ratio(neg log loss): 15.874431804140167 lowest: 0.935179205978811\n"
     ]
    }
   ],
   "source": [
    "sharpe_ratios=[abs(randomnized.cv_results_['mean_test_score'][i])/randomnized.cv_results_['std_test_score'][i]  for i in range(len(randomnized.cv_results_['mean_test_score']))]\n",
    "print('sharpe ratio(neg log loss):', max(sharpe_ratios), 'lowest:', min(sharpe_ratios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b615c",
   "metadata": {},
   "source": [
    "(b) Repeat point2.a,this time with accuracy as the scoring function.\n",
    "Compute the in-sample forecasts derived from the hyper-tuned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b6d9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AFML/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': np.float64(30.06683104508431), 'gamma': np.float64(0.05827034355380007)} 0.767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions={\n",
    "    'C':loguniform(1e-2, 100),\n",
    "    'gamma':loguniform(1e-2, 100)\n",
    "}\n",
    "cv=PurgedKFold(n_splits=10, t1=cont['t1'], pct_embargo=0.01)\n",
    "randomnized=RandomizedSearchCV(estimator=SVC(probability=True), param_distributions=param_distributions, scoring='accuracy', cv=cv, n_jobs=-1, n_iter=25)\n",
    "randomnized.fit(X=X, y=cont['bin'], sample_weight=cont['w'])\n",
    "print(randomnized.best_params_, randomnized.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebce75",
   "metadata": {},
   "source": [
    "(c) What scoring method leads tohigher (in-sample) Sharpe ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df30748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sharpe ratio(accuracy): 4.951149382485065 lowest: 0.5202088185650193\n"
     ]
    }
   ],
   "source": [
    "sharpe_ratios=[abs(randomnized.cv_results_['mean_test_score'][i])/randomnized.cv_results_['std_test_score'][i]  for i in range(len(randomnized.cv_results_['mean_test_score']))]\n",
    "print('sharpe ratio(accuracy):', max(sharpe_ratios), 'lowest:', min(sharpe_ratios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a6169",
   "metadata": {},
   "source": [
    "9.5 Read the definition of log loss, L[Y,P]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed655384",
   "metadata": {},
   "source": [
    "(a) Why is the scoring function neg_log_loss defined as the negative log loss, −L[Y,P]?\n",
    "1. 높은게 더 좋게 하기 위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810de0e",
   "metadata": {},
   "source": [
    "(b) What would be the outcome of maximizing the log loss,rather than the neg-\n",
    "ative log loss?\n",
    "1. 그 라벨을 맞추지 않도록 피팅을 하여 랜덤 예측보다 더 안 좋은 성능을 가진 모델을 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f6fc5",
   "metadata": {},
   "source": [
    "9.6 Consider an investment strategy that sizes its bets equally,regardless of thefore-\n",
    "cast’s confidence. In this case, what is a more appropriate scoring function for\n",
    "hyper-parameter tuning, accuracy or cross-entropy loss?\n",
    "\n",
    "1. 예측 확률 자체의 크기보다는 맞췄는지 그 자체인 hit-ratio가 중요하므로 accuracy가 더 적절하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f748b8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AFML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
